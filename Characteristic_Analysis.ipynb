{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8851f479-7eee-4505-94e2-c3c35e0c8be6",
   "metadata": {},
   "source": [
    "# Characteristic Analysis for LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf704ce-4c49-4ae2-8481-cf4db5a0efde",
   "metadata": {},
   "source": [
    "## Five Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "178fdd26-5f1d-48eb-89c5-19f90d17272e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample counts for each LLM model:\n",
      "Claude-3-haiku:\n",
      "  Train: 3102\n",
      "  Val: 775\n",
      "  Test:  969\n",
      "\n",
      "GPT-4o-mini:\n",
      "  Train: 3047\n",
      "  Val: 762\n",
      "  Test:  952\n",
      "\n",
      "Llama-3.2-3B-Instruct:\n",
      "  Train: 3174\n",
      "  Val: 794\n",
      "  Test:  993\n",
      "\n",
      "Phi-3-Mini-4K:\n",
      "  Train: 3198\n",
      "  Val: 800\n",
      "  Test:  1000\n",
      "\n",
      "Qwen2.5-3B-Instruct:\n",
      "  Train: 2979\n",
      "  Val: 745\n",
      "  Test:  931\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/CSE584_Midterm/Model_Evaluation/load_and_preprocess.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_df['LLM_encoded'] = le.fit_transform(combined_df['LLM'])\n"
     ]
    }
   ],
   "source": [
    "from Model_Evaluation.load_and_preprocess import load_and_preprocess_data, preprocess_data, create_data_loaders, TextDataset\n",
    "import numpy as np\n",
    "import random \n",
    "import pandas as pd\n",
    "\n",
    "# SEED FIXED\n",
    "SEED = 20241006\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "file_paths = ['DataSet/X_ij_samples_5k_Claude-3-haiku_5sentences.csv', \n",
    "              # 'DataSet/X_ij_samples_5k_Falcon-7b.csv', \n",
    "              'DataSet/X_ij_samples_5k_Qwen2.5-3B-Instruct_5sentences.csv',\n",
    "              'DataSet/X_ij_samples_5k_GPT-4o-mini_5sentences.csv',\n",
    "              'DataSet/X_ij_samples_5k_Llama-3.2-3B-Instruct_5sentences.csv',\n",
    "              # 'DataSet/X_ij_samples_5k_Llama-2-7b-chat.csv',\n",
    "              'DataSet/X_ij_samples_5k_Phi-3-Mini-4K_5sentences.csv']\n",
    "\n",
    "X_train, X_test, X_val, y_train, y_test, y_val, label_encoder, combined_df, combined_df_temp = load_and_preprocess_data(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff90a28-c72f-47a2-9307-9aa797ffd60f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      processed_text                    LLM\n",
      "0  but they all looked bland on my kitchen counte...  Llama-3.2-3B-Instruct\n",
      "1  my world before you came and turned everything...  Llama-3.2-3B-Instruct\n",
      "2  after two hours , she was still working on her...    Qwen2.5-3B-Instruct\n",
      "3  the rest of the dress hugged my figure beautif...    Qwen2.5-3B-Instruct\n",
      "4  her eyes whipped around the room, searching fo...         Claude-3-haiku\n"
     ]
    }
   ],
   "source": [
    "def restore_test_dataframe(X_test, y_test, label_encoder):\n",
    "    \n",
    "    y_test_labels = label_encoder.inverse_transform(y_test)\n",
    "    \n",
    "    restored_df = pd.DataFrame({\n",
    "        'processed_text': X_test,  \n",
    "        'LLM': y_test_labels       \n",
    "    })\n",
    "    \n",
    "    return restored_df\n",
    "\n",
    "restored_test_df = restore_test_dataframe(X_test, y_test, label_encoder)\n",
    "\n",
    "print(restored_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1caedf4e-a9c2-4391-87ae-56ce1a51cd70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = combined_df.reset_index(drop=True)\n",
    "# df = restored_test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1208d6-e615-4cb6-be4a-8f6abf8d458b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### N-gram Frequency Analysis (Bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2df9ac6-0f27-45cf-802f-8a5aebdbe944",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Bigrams for Claude-3-haiku:\n",
      "deep breath       199\n",
      "felt sense        195\n",
      "moving forward    131\n",
      "hard work         127\n",
      "couldn help       126\n",
      "dtype: int64\n",
      "\n",
      "Top Bigrams for Qwen2.5-3B-Instruct:\n",
      "felt like              288\n",
      "yesterday evening      286\n",
      "yesterday morning      184\n",
      "yesterday afternoon    112\n",
      "feels like              92\n",
      "dtype: int64\n",
      "\n",
      "Top Bigrams for GPT-4o-mini:\n",
      "deep breath    292\n",
      "took deep      176\n",
      "felt sense     172\n",
      "filled air     127\n",
      "hard work      123\n",
      "dtype: int64\n",
      "\n",
      "Top Bigrams for Llama-3.2-3B-Instruct:\n",
      "couldn help    225\n",
      "felt like      116\n",
      "living room     94\n",
      "best friend     85\n",
      "coffee shop     74\n",
      "dtype: int64\n",
      "\n",
      "Top Bigrams for Phi-3-Mini-4K:\n",
      "felt sense       131\n",
      "living room      119\n",
      "couldn help      115\n",
      "end day          109\n",
      "floor cleaner     93\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2), stop_words='english')  \n",
    "X = vectorizer.fit_transform(df['processed_text'])\n",
    "\n",
    "ngram_freq = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "ngram_freq['LLM'] = df['LLM']\n",
    "\n",
    "for llm in df['LLM'].unique():\n",
    "    print(f\"\\nTop Bigrams for {llm}:\")\n",
    "    llm_ngrams = ngram_freq[ngram_freq['LLM'] == llm].drop('LLM', axis=1).sum().sort_values(ascending=False).head(5)\n",
    "    print(llm_ngrams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bcab5e-97db-420e-9771-a0d7d1d10c62",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e125972b-499e-4365-8435-116eaa55b58a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 1:\n",
      "['home', 'yesterday', 'friend', 'today', 'soon', 'just', 'work', 'quickly', 'time', 'like']\n",
      "\n",
      "Topic 2:\n",
      "['clear', 'people', 'challenges', 'sense', 'life', 'felt', 'experience', 'mind', 'despite', 'ultimately']\n",
      "\n",
      "Topic 3:\n",
      "['help', 'make', 'home', 'family', 'work', 'friends', 'decided', 'day', 'time', 'new']\n",
      "\n",
      "Topic 4:\n",
      "['park', 'away', 'laughter', 'day', 'air', 'felt', 'eyes', 'filled', 'moment', 'room']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=100)\n",
    "count_data = count_vectorizer.fit_transform(df['processed_text'])\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=4, random_state=20241016)\n",
    "lda.fit(count_data)\n",
    "\n",
    "topic_distribution = lda.transform(count_data)\n",
    "df['Topic_1'] = topic_distribution[:, 0]\n",
    "df['Topic_2'] = topic_distribution[:, 1]\n",
    "df['Topic_3'] = topic_distribution[:, 2]\n",
    "df['Topic_4'] = topic_distribution[:, 3]\n",
    "# print(df[['LLM', 'Topic_1', 'Topic_2']])\n",
    "\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "    print(f\"\\nTopic {idx+1}:\")\n",
    "    print([count_vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b58e998a-ccdf-4ca6-add8-6e33dcf0a7ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_topic_distribution:\n",
      "                     LLM   Topic_1   Topic_2   Topic_3   Topic_4\n",
      "0         Claude-3-haiku  0.163721  0.326478  0.245243  0.264559\n",
      "1            GPT-4o-mini  0.141053  0.291688  0.223890  0.343369\n",
      "2  Llama-3.2-3B-Instruct  0.273114  0.170729  0.296453  0.259704\n",
      "3          Phi-3-Mini-4K  0.185405  0.213478  0.306135  0.294982\n",
      "4    Qwen2.5-3B-Instruct  0.393773  0.132102  0.275452  0.198673\n"
     ]
    }
   ],
   "source": [
    "# LLM별 주제 분포 평균 계산\n",
    "average_topic_distribution = df.groupby('LLM')[['Topic_1', 'Topic_2', 'Topic_3', 'Topic_4']].mean().reset_index()\n",
    "\n",
    "print(\"average_topic_distribution:\")\n",
    "print(average_topic_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2295ceaf-6482-4b92-a3d7-df69da0b225b",
   "metadata": {},
   "source": [
    "## Single Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "902e5452-fd26-4e26-80ab-f46b669cce38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample counts for each LLM model:\n",
      "Claude-3-haiku:\n",
      "  Train: 3179\n",
      "  Val: 795\n",
      "  Test:  993\n",
      "\n",
      "Falcon-7b:\n",
      "  Train: 3168\n",
      "  Val: 792\n",
      "  Test:  990\n",
      "\n",
      "GPT-4o-mini:\n",
      "  Train: 3198\n",
      "  Val: 800\n",
      "  Test:  1000\n",
      "\n",
      "Llama-2-7b-chat:\n",
      "  Train: 3182\n",
      "  Val: 796\n",
      "  Test:  994\n",
      "\n",
      "Llama-3.2-3B-Instruct:\n",
      "  Train: 3198\n",
      "  Val: 799\n",
      "  Test:  1000\n",
      "\n",
      "Phi-3-Mini-4K:\n",
      "  Train: 3197\n",
      "  Val: 800\n",
      "  Test:  1000\n",
      "\n",
      "Qwen2.5-3B-Instruct:\n",
      "  Train: 3178\n",
      "  Val: 794\n",
      "  Test:  993\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/CSE584_Midterm/Model_Evaluation/load_and_preprocess.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_df['LLM_encoded'] = le.fit_transform(combined_df['LLM'])\n"
     ]
    }
   ],
   "source": [
    "from Model_Evaluation.load_and_preprocess import load_and_preprocess_data, preprocess_data, create_data_loaders, TextDataset\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "# SEED FIXED\n",
    "SEED = 20241006\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "file_paths = ['DataSet/X_ij_samples_5k_Claude-3-haiku.csv', \n",
    "              'DataSet/X_ij_samples_5k_Falcon-7b.csv', \n",
    "              'DataSet/X_ij_samples_5k_Qwen2.5-3B-Instruct.csv',\n",
    "              'DataSet/X_ij_samples_5k_GPT-4o-mini.csv',\n",
    "              'DataSet/X_ij_samples_5k_Llama-3.2-3B-Instruct.csv',\n",
    "              'DataSet/X_ij_samples_5k_Llama-2-7b-chat.csv',\n",
    "              'DataSet/X_ij_samples_5k_Phi-3-Mini-4K.csv']\n",
    "\n",
    "X_train, X_test, X_val, y_train, y_test, y_val, label_encoder, combined_df_1sen, combined_df_temp = load_and_preprocess_data(file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a371cf9a-e8f9-49d4-bb3b-c1e82ea22199",
   "metadata": {},
   "source": [
    "### N-gram Frequency Analysis (Bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7d30a78-4483-46f6-b7f7-e64efbea971e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Bigrams for Claude-3-haiku:\n",
      "late meeting        33\n",
      "surprise party      25\n",
      "deep breath         22\n",
      "beautiful sunset    21\n",
      "felt sense          18\n",
      "dtype: int64\n",
      "\n",
      "Top Bigrams for Falcon-7b:\n",
      "walked away          30\n",
      "deep breath          27\n",
      "gravity situation    25\n",
      "sight behold         23\n",
      "realized gravity     18\n",
      "dtype: int64\n",
      "\n",
      "Top Bigrams for Qwen2.5-3B-Instruct:\n",
      "yesterday evening    84\n",
      "yesterday morning    28\n",
      "dinner tonight       19\n",
      "work today           18\n",
      "late appointment     15\n",
      "dtype: int64\n",
      "\n",
      "Top Bigrams for GPT-4o-mini:\n",
      "felt sense          30\n",
      "beautiful sunset    29\n",
      "finish homework     22\n",
      "deep breath         22\n",
      "finish project      20\n",
      "dtype: int64\n",
      "\n",
      "Top Bigrams for Llama-3.2-3B-Instruct:\n",
      "high school       35\n",
      "best friend       35\n",
      "living room       34\n",
      "birthday party    32\n",
      "felt like         31\n",
      "dtype: int64\n",
      "\n",
      "Top Bigrams for Llama-2-7b-chat:\n",
      "home work            23\n",
      "late work            21\n",
      "finished homework    19\n",
      "video games          19\n",
      "walked away          16\n",
      "dtype: int64\n",
      "\n",
      "Top Bigrams for Phi-3-Mini-4K:\n",
      "living room      25\n",
      "grocery store    22\n",
      "cup coffee       15\n",
      "walk park        15\n",
      "deep breath      14\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df2 = combined_df_1sen.reset_index(drop=True)\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2), stop_words='english')  \n",
    "X = vectorizer.fit_transform(df2['processed_text'])\n",
    "ngram_freq = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "ngram_freq['LLM'] = df2['LLM']\n",
    "\n",
    "for llm in df2['LLM'].unique():\n",
    "    print(f\"\\nTop Bigrams for {llm}:\")\n",
    "    llm_ngrams = ngram_freq[ngram_freq['LLM'] == llm].drop('LLM', axis=1).sum().sort_values(ascending=False).head(5)\n",
    "    print(llm_ngrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d77d6d7-9dec-4890-a948-b88fd4c48b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d84aad-f739-486d-8fc3-5f441419818e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a153a350-f782-49e1-9a2f-9914d270cb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce6b3dd-da0e-46a3-b7e5-de6c2533b540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0de3105e-297b-4fdc-b055-8cb0364ece99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  LLM       TTR\n",
      "0      Claude-3-haiku  0.769231\n",
      "1      Claude-3-haiku  0.833333\n",
      "2      Claude-3-haiku  0.813559\n",
      "3      Claude-3-haiku  0.803030\n",
      "4      Claude-3-haiku  0.788732\n",
      "...               ...       ...\n",
      "24995   Phi-3-Mini-4K  0.800000\n",
      "24996   Phi-3-Mini-4K  0.859649\n",
      "24997   Phi-3-Mini-4K  0.836066\n",
      "24998   Phi-3-Mini-4K  0.847826\n",
      "24999   Phi-3-Mini-4K  0.900000\n",
      "\n",
      "[24221 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def calculate_ttr(text):\n",
    "    tokens = text.split()\n",
    "    return len(set(tokens)) / len(tokens)\n",
    "\n",
    "combined_df_1sen['TTR'] = combined_df_1sen['processed_text'].apply(calculate_ttr)\n",
    "print(df[['LLM', 'TTR']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0b8bdee-41b4-4f18-8e99-40827fe02e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LLM</th>\n",
       "      <th>TTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claude-3-haiku</td>\n",
       "      <td>0.961883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4o-mini</td>\n",
       "      <td>0.958474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-3.2-3B-Instruct</td>\n",
       "      <td>0.972893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phi-3-Mini-4K</td>\n",
       "      <td>0.946084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qwen2.5-3B-Instruct</td>\n",
       "      <td>0.977158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     LLM       TTR\n",
       "0         Claude-3-haiku  0.961883\n",
       "1            GPT-4o-mini  0.958474\n",
       "2  Llama-3.2-3B-Instruct  0.972893\n",
       "3          Phi-3-Mini-4K  0.946084\n",
       "4    Qwen2.5-3B-Instruct  0.977158"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_metrics = combined_df_1sen.groupby('LLM').mean('TTR').reset_index()\n",
    "average_metrics[['LLM', 'TTR']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e514ff-2733-423a-a747-922e5d7d23a7",
   "metadata": {},
   "source": [
    "Vocabulary Richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a27735c-0c21-4372-a1db-15adddfa41bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_ttr(text):\n",
    "    tokens = text.split()\n",
    "    return len(set(tokens)) / len(tokens)\n",
    "\n",
    "df['TTR'] = df['processed_text'].apply(calculate_ttr)\n",
    "print(df[['LLM', 'TTR']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4518f7-13aa-4c3e-b4e4-2204d6d1445c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "average_metrics = df.groupby('LLM').mean('TTR').reset_index()\n",
    "average_metrics[['LLM', 'TTR', 'NOUN', 'VERB', 'ADJ', 'ADV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938cabbe-a76b-47f6-9923-01318e651403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def pos_tag_distribution(text):\n",
    "    doc = nlp(text)\n",
    "    pos_counts = Counter([token.pos_ for token in doc])\n",
    "    total = sum(pos_counts.values())\n",
    "    return {pos: count / total for pos, count in pos_counts.items()}\n",
    "\n",
    "pos_distribution = df['processed_text'].apply(pos_tag_distribution).apply(pd.Series).fillna(0)\n",
    "df = pd.concat([df, pos_distribution], axis=1)\n",
    "print(df[['LLM', 'NOUN', 'VERB', 'ADJ', 'ADV']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5943079f-cc95-4e35-8f5a-d4250b4ede03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af22f1f0-f448-438a-9a40-202124040726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
    "\n",
    "df[['Sentiment_Polarity', 'Sentiment_Subjectivity']] = df['processed_text'].apply(lambda x: pd.Series(get_sentiment(x)))\n",
    "print(df[['LLM', 'Sentiment_Polarity', 'Sentiment_Subjectivity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b73a5d-c0fa-4692-b1e7-189565c26775",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "grouped_stats = df.groupby('LLM').agg({\n",
    "    'Sentiment_Polarity': ['mean', 'std', 'min', 'max', 'median', lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)],\n",
    "    'Sentiment_Subjectivity': ['mean', 'std', 'min', 'max', 'median', lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)]\n",
    "})\n",
    "\n",
    "\n",
    "grouped_stats.columns = ['_'.join(col).strip() for col in grouped_stats.columns.values]\n",
    "\n",
    "print(grouped_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377d48e-5f19-4882-a904-132a67639e05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "embeddings = model.encode(df['processed_text'].tolist())\n",
    "\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=df['LLM'], columns=df['LLM'])\n",
    "# print(similarity_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5464aae3-37d5-4990-b14e-e53800f323b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=df.index, columns=df.index)\n",
    "\n",
    "for llm in df['LLM'].unique():\n",
    "\n",
    "    indices = df[df['LLM'] == llm].index\n",
    "    \n",
    "\n",
    "    llm_similarity_matrix = similarity_df.loc[indices, indices]\n",
    "    \n",
    "\n",
    "    print(f\"\\nSimilarity Matrix for {llm}:\")\n",
    "    print(llm_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b200d86-ffac-45e7-88ca-11913c76091a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c9bb7b-85be-4e69-9d86-08eaf2960156",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = np.array(embeddings)  \n",
    "\n",
    "grouped_embeddings = df.groupby('LLM').apply(lambda x: embeddings[x.index - df.index[0]].mean(axis=0))\n",
    "\n",
    "group_similarity_matrix = cosine_similarity(grouped_embeddings.tolist())\n",
    "\n",
    "group_similarity_df = pd.DataFrame(group_similarity_matrix, index=df['LLM'].unique(), columns=df['LLM'].unique())\n",
    "\n",
    "print(\"\\nLLM Group Similarity Matrix:\")\n",
    "print(group_similarity_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
